---
layout: post
title:  "Rule Relevance Score"
categories: explainable-ai local-to-global tabular-data
---


RRS (Rule-Relevance Score) is a scoring-based approach tackling the [Local to Global]({{ site.baseurl }}/2019/local_to_global_problem/) problem.

<div class="ui icon buttons">
	<button class="ui active button paper">
	  <i class="far fa-file-pdf"></i>
	  Paper
	</button>

	<a href="https://drive.google.com/file/d/1YlYNMG0eUmWR3loFOOX3OQ4PMct0gdyr/view?usp=sharing" target="_blank">
	<button class="ui active button presentation">
	  <i class="far fa-image"></i>
	  Poster
	</button>
	</a>
</div>

## Algorithm
RRS's definition is pretty straightforward:
```python
def rrs(rules, weights, x, y, beta):
	# Score the given rules
	scores = score(rules, weights, x, y, beta)
	betath_percentile = percentile(scores, beta)
	output_rules = [rule for rule, score in zip(rules, scores) if score >= betath_percentile]

	return output_rules
```
In Line 2 we perform the core operation of the framework by scoring each rule on the given trainin set `(x, y)` with a set of hyperparameter weights `weights`.
Then, in Line 3 and 4, we select the cutting threshold for the score by leveraging the `beta` percentile of the scores vector.
Finally, in Line 6, we filter out the rules with a score lower than the computed threshold.

## Scoring
In order to score, we need to introduce three metrics: the *coverage* of a rule, the *perfect coverage* of a rule, the *association score*

#### Coverage
A rule $r$ is said to have _coverage_ on a record if the record satisfies $r$'s premises. For instance, for a rule

<p class="example">
	{salary $\geq 10k$, savings $\geq 40k$} $\rightarrow$ Granted,
</p>

a record `salary = 15k, savings = 50k` would be _covered_, while a record `salary = 20k, savings = 30k` would not. The coverage score $c(r, x)$of a rule $r$ on a dataset $(X, \cdot)$ is simply its normalized coverage:

$$
	c(r, X) = \dfrac{1}{|X|} \sum\limits_{x \in X} 1_{cov(r, x)},
$$

where $1_{cov(r, x)}$ is the characteristic function of the coverage.

#### Perfect coverage
A rule $r$ is said to have _perfect coverage_ on a record if the record satisfies $r$'s premises and its label. For instance, for a rule

<p class="example">
	{salary $\geq 10k$, savings $\geq 40k$} $\rightarrow$ Granted,
</p>

a record `salary = 15k, savings = 50k, y = Granted` would be _covered_, while a record `salary = 15k, savings = 50k, y = Not granted` would not. The perfect coverage score $\tilde{c}(r, x)$of a rule $r$ on a dataset $(X, y)$ is simply its normalized coverage:

$$
	c(r, X) = \dfrac{1}{|X|} \sum\limits_{x \in X} 1_{\widetilde{cov}(r, x)},
$$

where $1_{\widetilde{cov}(r, x)}$ is the characteristic function of the perfect coverage.

---

## Sparsity
The sparsity of a rule is measured as the average distance between the covered records:

$$
	s(r, x) = \dfrac{1}{D} \sum\limits_{x \in X} \sum\limits_{x' \in X} \mid\mid x - x'\mid\mid^2,
$$

where $D$ is a normalization factor which restricts the score between $0$ and $1$.

---

## Association score
The association score evaluates the ability of a rule to cover outlier records in the datasets, that is, records which are not covered by many rules.
It is defined as the normalized inverse coverage:

$$
	a(r, X) = C(R, X)c(r, X)^{-1})^{-1},
$$

where $C(R, X)$ is the coverage matrix of the whole input ruleset $R$.

### Perfect Association score
The perfect association score restricts the association score to records on which the rule has perfect coverage:

$$
	a(r, X, Y) = \tilde{C}(R, X) \tilde{c}(r, X^{-1})^{-1},
$$

where $\tilde{C}(R, X)$ is the perfect coverage matrix of the whole input ruleset $R$.

---

# Final scoring
The full scoring is given by a weighted sum of the above scoring vectors:

$$
	rrs(r, X, Y) = \alpha_1 \cdot c + \alpha_2 \cdot s + \alpha_3 \cdot a + \alpha_4 \cdot \tilde{c} + \alpha_5 \cdot \tilde{a}
$$
